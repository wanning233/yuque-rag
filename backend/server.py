# server.py

from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from fastapi.middleware.cors import CORSMiddleware
from app import initialize_retriever_and_llm
import json
from typing import AsyncGenerator

# åˆå§‹åŒ– RAG æ¨¡å‹
retriever, llm = initialize_retriever_and_llm()

# åˆ›å»º FastAPI åº”ç”¨ï¼Œé…ç½® Swagger æ–‡æ¡£
app = FastAPI(
    title="è¯­é›€ RAG é—®ç­”ç³»ç»Ÿ API",
    description="""
    åŸºäºè¯­é›€çŸ¥è¯†åº“çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰é—®ç­”ç³»ç»Ÿã€‚
    
    ## åŠŸèƒ½ç‰¹æ€§
    - ğŸ“š çŸ¥è¯†åº“æ£€ç´¢é—®ç­”
    - ğŸ”„ æµå¼å“åº”æ”¯æŒ
    - ğŸ¤– æ”¯æŒæœ¬åœ°/è¿œç¨‹å¤§æ¨¡å‹
    - ğŸ” ä¸¤é˜¶æ®µæ£€ç´¢ï¼ˆå‘é‡ + é‡æ’åºï¼‰
    
    ## ä½¿ç”¨è¯´æ˜
    1. ä½¿ç”¨ `/chat` æ¥å£è¿›è¡Œå¸¸è§„é—®ç­”ï¼ˆä¸€æ¬¡æ€§è¿”å›ï¼‰
    2. ä½¿ç”¨ `/chat/stream` æ¥å£è·å–æµå¼å“åº”ï¼ˆå®æ—¶æ‰“å­—æ•ˆæœï¼‰
    3. ä½¿ç”¨ `/health` æ¥å£æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
    """,
    version="1.0.0",
    contact={
        "name": "Yuque RAG Project",
    },
    license_info={
        "name": "Apache 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.html",
    },
)

# å…è®¸è·¨åŸŸè®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============== æ•°æ®æ¨¡å‹ ==============

class QueryRequest(BaseModel):
    """é—®ç­”è¯·æ±‚æ¨¡å‹"""
    question: str = Field(
        ..., 
        description="ç”¨æˆ·æå‡ºçš„é—®é¢˜",
        example="å››æœˆè¯­é›€æœ‰å“ªäº›æ›´æ–°ï¼Ÿ"
    )

class ChatResponse(BaseModel):
    """é—®ç­”å“åº”æ¨¡å‹"""
    answer: str = Field(
        ..., 
        description="ç³»ç»Ÿç”Ÿæˆçš„å›ç­”",
        example="å››æœˆè¯­é›€çš„æ›´æ–°åŒ…æ‹¬æ–°å¢äº†å›¢é˜Ÿåä½œåŠŸèƒ½ï¼Œä¼˜åŒ–äº†æ–‡æ¡£ç¼–è¾‘ä½“éªŒï¼Œä»¥åŠå¢å¼ºäº†å®‰å…¨ç­–ç•¥ã€‚"
    )

class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”æ¨¡å‹"""
    status: str = Field(..., description="æœåŠ¡çŠ¶æ€", example="ok")
    message: str = Field(..., description="çŠ¶æ€ä¿¡æ¯", example="ç³»ç»Ÿè¿è¡Œæ­£å¸¸")


# ============== API æ¥å£ ==============

@app.get(
    "/health",
    response_model=HealthResponse,
    tags=["ç³»ç»Ÿ"],
    summary="å¥åº·æ£€æŸ¥",
    description="æ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€"
)
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£ï¼Œç”¨äºç›‘æ§ç³»ç»ŸçŠ¶æ€ã€‚
    
    Returns:
        HealthResponse: åŒ…å«ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
    """
    return {
        "status": "ok",
        "message": "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
    }


@app.post(
    "/chat",
    response_model=ChatResponse,
    tags=["é—®ç­”"],
    summary="é—®ç­”æ¥å£ï¼ˆä¸€æ¬¡æ€§è¿”å›ï¼‰",
    description="å‘ç³»ç»Ÿæé—®å¹¶è·å–å®Œæ•´ç­”æ¡ˆï¼ˆéæµå¼ï¼‰"
)
def chat(req: QueryRequest):
    """
    å¸¸è§„é—®ç­”æ¥å£ï¼Œè¿”å›å®Œæ•´çš„ç­”æ¡ˆã€‚
    
    Args:
        req: åŒ…å«ç”¨æˆ·é—®é¢˜çš„è¯·æ±‚ä½“
        
    Returns:
        ChatResponse: åŒ…å«ç”Ÿæˆçš„ç­”æ¡ˆ
        
    Example:
        ```json
        POST /chat
        {
            "question": "ä»€ä¹ˆæ˜¯RAGï¼Ÿ"
        }
        ```
    """
    query = req.question.strip()
    if not query:
        return {"answer": "â—è¯·è¾“å…¥é—®é¢˜"}

    relevant_docs = retriever.invoke(query)
    context = "\n\n".join([doc.page_content for doc in relevant_docs])
    prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{query}\n\nå›ç­”ï¼š"
    answer = llm.generate(prompt)

    return {"answer": answer}


@app.post(
    "/chat/stream",
    tags=["é—®ç­”"],
    summary="é—®ç­”æ¥å£ï¼ˆæµå¼è¿”å›ï¼‰",
    description="å‘ç³»ç»Ÿæé—®å¹¶è·å–æµå¼ç­”æ¡ˆï¼ˆSSEæ ¼å¼ï¼Œæ”¯æŒå®æ—¶æ‰“å­—æ•ˆæœï¼‰",
    responses={
        200: {
            "description": "æˆåŠŸè¿”å›æµå¼æ•°æ®",
            "content": {
                "text/event-stream": {
                    "example": "data: {\"content\": \"ä½ \"}\n\ndata: {\"content\": \"å¥½\"}\n\n"
                }
            }
        }
    }
)
async def chat_stream(req: QueryRequest):
    """
    æµå¼é—®ç­”æ¥å£ï¼Œä½¿ç”¨ Server-Sent Events (SSE) è¿”å›ç­”æ¡ˆã€‚
    
    é€‚ç”¨äºéœ€è¦å®æ—¶å±•ç¤ºå›ç­”è¿›åº¦çš„åœºæ™¯ï¼ˆå¦‚å‰ç«¯æ‰“å­—æœºæ•ˆæœï¼‰ã€‚
    
    Args:
        req: åŒ…å«ç”¨æˆ·é—®é¢˜çš„è¯·æ±‚ä½“
        
    Returns:
        StreamingResponse: SSE æ ¼å¼çš„æµå¼å“åº”
        
    Example:
        ```javascript
        const eventSource = new EventSource('/chat/stream', {
            method: 'POST',
            body: JSON.stringify({question: 'ä»€ä¹ˆæ˜¯RAGï¼Ÿ'})
        });
        
        eventSource.onmessage = (event) => {
            const data = JSON.parse(event.data);
            console.log(data.content); // é€å­—è¾“å‡º
        };
        ```
    """
    query = req.question.strip()
    
    async def generate_stream() -> AsyncGenerator[str, None]:
        if not query:
            yield f"data: {json.dumps({'content': 'â—è¯·è¾“å…¥é—®é¢˜', 'done': True}, ensure_ascii=False)}\n\n"
            return
        
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            relevant_docs = retriever.invoke(query)
            context = "\n\n".join([doc.page_content for doc in relevant_docs])
            prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{query}\n\nå›ç­”ï¼š"
            
            # æµå¼ç”Ÿæˆç­”æ¡ˆ
            for chunk in llm.generate_stream(prompt):
                yield f"data: {json.dumps({'content': chunk}, ensure_ascii=False)}\n\n"
            
            # å‘é€å®Œæˆæ ‡è®°
            yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e), 'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨nginxç¼“å†²
        }
    )
