# loader/yuque_loader.py

import requests
import time
from langchain.schema import Document
from typing import List, Optional


class YuqueLoader:
    def __init__(self, token: str, timeout: int = 60, max_retries: int = 3):
        self.token = token
        self.base_url = "https://www.yuque.com/api/v2"
        self.headers = {
            "X-Auth-Token": self.token,
            "Content-Type": "application/json",
        }
        self.timeout = timeout
        self.max_retries = max_retries


    # ---------- åŸºç¡€ API ---------- #
    def _get(self, url: str) -> dict:
        """å¸¦é‡è¯•æœºåˆ¶çš„GETè¯·æ±‚"""
        last_error = None
        for attempt in range(self.max_retries):
            try:
                resp = requests.get(url, headers=self.headers, timeout=self.timeout)
                resp.raise_for_status()
                return resp.json().get("data", [])
            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                    print(f"âš ï¸  è¯·æ±‚è¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{self.max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡")
                    raise
            except requests.exceptions.RequestException as e:
                print(f"âŒ è¯·æ±‚é”™è¯¯: {e}")
                raise
        
        if last_error:
            raise last_error

    def get_repos(self, group_login: str):
        return self._get(f"{self.base_url}/groups/{group_login}/repos")

    def get_docs_list(self, namespace: str):
        return self._get(f"{self.base_url}/repos/{namespace}/docs")

    def get_doc_content(self, namespace: str, slug: str) -> str:
        url = f"{self.base_url}/repos/{namespace}/docs/{slug}"
        last_error = None
        for attempt in range(self.max_retries):
            try:
                resp = requests.get(url, headers=self.headers, timeout=self.timeout)
                resp.raise_for_status()
                return resp.json()["data"]["body"]  # markdown / html
            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"   âš ï¸  æ–‡æ¡£ '{slug}' è·å–è¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{self.max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"   âŒ æ–‡æ¡£ '{slug}' è·å–å¤±è´¥ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡ï¼Œè·³è¿‡æ­¤æ–‡æ¡£")
                    return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯å¤±è´¥
            except requests.exceptions.RequestException as e:
                print(f"   âŒ æ–‡æ¡£ '{slug}' è¯·æ±‚é”™è¯¯: {e}ï¼Œè·³è¿‡æ­¤æ–‡æ¡£")
                return ""
        
        if last_error:
            print(f"   âš ï¸  æ–‡æ¡£ '{slug}' æœ€ç»ˆè·å–å¤±è´¥ï¼Œè·³è¿‡")
            return ""


    # ---------- æ€»å…¥å£ ---------- #
    def load_documents(
        self,
        *,
        group_login: Optional[str] = None,
        namespace: Optional[str] = None,
    ) -> List[Document]:
        """
        Â· group_login â†’ åŠ è½½è¯¥å›¢é˜Ÿä¸‹æ‰€æœ‰ repo
        Â· namespace   â†’ ä»…åŠ è½½å•ä¸€ repo
        """
        if not (group_login or namespace):
            raise ValueError("å¿…é¡»æä¾› group_login æˆ– namespace å…¶ä¸­ä¹‹ä¸€")

        documents: List[Document] = []

        def _collect(ns: str):
            docs_list = self.get_docs_list(ns)
            total = len(docs_list)
            print(f"   ğŸ“„ å…±æ‰¾åˆ° {total} ç¯‡æ–‡æ¡£")
            
            for idx, meta in enumerate(docs_list, 1):
                slug = meta["slug"]
                title = meta.get("title", slug)
                print(f"   [{idx}/{total}] æ­£åœ¨è·å–: {title}")
                
                content = self.get_doc_content(ns, slug)
                
                # è·³è¿‡ç©ºæ–‡æ¡£
                if not content or not content.strip():
                    print(f"   âš ï¸  æ–‡æ¡£ '{title}' å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                    continue

                metadata = {
                    "repo": ns,
                    "doc_id": meta["id"],
                    "title": title,
                    "author_name": meta.get("user", {}).get("name", ""),
                    "created_at": meta["created_at"],
                }

                documents.append(Document(page_content=content, metadata=metadata))
                print(f"   âœ… æˆåŠŸåŠ è½½: {title}")

        if namespace:
            print(f"ğŸ“š è¯»å–æŒ‡å®šçŸ¥è¯†åº“ï¼š{namespace}")
            _collect(namespace)
        else:  # group_login mode
            repos = self.get_repos(group_login)
            print(f"ğŸ“š å›¢é˜Ÿ '{group_login}' å…±æœ‰ {len(repos)} ä¸ªçŸ¥è¯†åº“")
            for idx, repo in enumerate(repos, 1):
                ns = repo["namespace"]
                repo_name = repo.get("name", ns)
                print(f"\n[{idx}/{len(repos)}] è¯»å–çŸ¥è¯†åº“ï¼š{repo_name} ({ns})")
                _collect(ns)

        return documents

