# app.py

import os
# âš ï¸ å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ["HF_HOME"] = "./models"
os.environ["TRANSFORMERS_CACHE"] = "./models"

from loader.yuque_loader import YuqueLoader
from loader.text_preprocessor import TextPreprocessor
from embedder.bc_embedding import BCEmbeddingWrapper
from vectorstore.faiss_store import FaissVectorStore
from retriever.rerank_retriever import RerankRetriever
from llm.ollama_llm import OllamaLLM
from llm.openai_llm import OpenAILLM
from tools.web_search import WebSearchTool

from config import (
    FAISS_INDEX_PATH,
    VECTOR_DIM,
    BC_EMBED_MODEL,
    BC_RERANK_MODEL,
    OLLAMA_MODEL,
    USE_OPENAI,
    OPENAI_API_KEY,
    OPENAI_MODEL,
    OPENAI_API_BASE,
    QA_MODE,
    TOP_K_INITIAL,
    TOP_K_RERANK,
    YUQUE_TOKEN,
    YUQUE_GROUP,
    YUQUE_NAMESPACE
)

def initialize_retriever_and_llm():
    # ===== é…ç½®éƒ¨åˆ† =====
    yuque_token = YUQUE_TOKEN
    group_login = YUQUE_GROUP            # å›¢é˜Ÿåï¼ˆåŠ è½½æ•´ä¸ªå›¢é˜ŸçŸ¥è¯†åº“ï¼‰
    namespace = YUQUE_NAMESPACE          # ä¸ä¸ºç©ºåˆ™åŠ è½½å•ä¸€çŸ¥è¯†åº“

    embed_model_name = BC_EMBED_MODEL
    rerank_model_name = BC_RERANK_MODEL

    # ===== å°è¯•åŠ è½½å·²æœ‰ç´¢å¼• =====
    faiss_store = FaissVectorStore(vector_dim=VECTOR_DIM, index_path=FAISS_INDEX_PATH)
    index_exists = os.path.exists(FAISS_INDEX_PATH) and os.path.exists(FAISS_INDEX_PATH + ".docs.pkl")

    # ===== åŠ è½½BCEmbeddingæ¨¡å‹ï¼ˆé¢„å¤„ç†æ¨¡å¼å’Œé—®ç­”æ¨¡å¼éƒ½ç”¨åˆ°ï¼‰=====
    print("ğŸ§  åˆå§‹åŒ– BCEmbedding æ¨¡å‹...")
    bc_embedding = BCEmbeddingWrapper(embed_model_name, rerank_model_name)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç´¢å¼•åŠæ–‡æ¡£ï¼Œæˆ–å…³é—­äº†çº¯é—®ç­”æ¨¡å¼
    if not index_exists or not QA_MODE:
        print("ğŸ§© è¿›å…¥æ•°æ®æŒä¹…åŒ–æ¨¡å¼...")

        # ===== åŠ è½½æ–‡æ¡£ =====
        print("ğŸ” æ­£åœ¨åŠ è½½è¯­é›€çŸ¥è¯†åº“æ–‡æ¡£...")
        loader = YuqueLoader(yuque_token)
        documents = loader.load_documents(group_login=group_login, namespace=namespace)
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(documents)} ç¯‡æ–‡æ¡£")

        # ===== æ–‡æœ¬é¢„å¤„ç†ï¼ˆæ¸…æ´—ä¸åˆ‡åˆ†ï¼‰ =====
        print("ğŸ§¹ æ­£åœ¨æ¸…æ´—ä¸åˆ‡åˆ†æ–‡æ¡£...")
        preprocessor = TextPreprocessor()
        documents = preprocessor.process_documents(documents)
        print(f"âœ… æ¸…æ´—ä¸åˆ‡åˆ†å®Œæˆï¼Œå…± {len(documents)} æ®µæ–‡æœ¬")


        # ===== å‘é‡åŒ–æ–‡æ¡£å†…å®¹ =====
        print("ğŸ”¢ æ­£åœ¨ç”Ÿæˆæ–‡æ¡£å‘é‡...")
        texts = [doc.page_content for doc in documents]
        embeddings = bc_embedding.embed_texts(texts)

        # ===== æ„å»ºå‘é‡ç´¢å¼• =====
        print("ğŸ“¦ æ„å»º FAISS å‘é‡ç´¢å¼•...")
        faiss_store.add_embeddings(embeddings, documents)
        faiss_store.save()
        print("âœ… æ•°æ®æŒä¹…åŒ–å®Œæˆ")

    else:
        print("ğŸ“¥ åŠ è½½å·²æœ‰å‘é‡ç´¢å¼•...")
        faiss_store.load()

    documents = faiss_store.documents

    # ===== æ£€ç´¢å™¨ï¼ˆå¸¦é‡æ’åºï¼‰ =====
    retriever = RerankRetriever(
        faiss_store=faiss_store,
        bc_embedding_wrapper=bc_embedding,
        documents=documents,
        top_k_initial=TOP_K_INITIAL,
        top_k_rerank=TOP_K_RERANK
    )

    # ===== åˆå§‹åŒ– LLM =====
    if USE_OPENAI:
        print("ğŸŒ ä½¿ç”¨ OpenAI API æ¨¡å‹")
        llm = OpenAILLM(
            model_name=OPENAI_MODEL,
            api_key=OPENAI_API_KEY,
            api_base=OPENAI_API_BASE  # âœ… ä¼ å…¥ base_url
        )
    else:
        print("ğŸ–¥ï¸ ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹")
        llm = OllamaLLM(OLLAMA_MODEL)

    return retriever, llm

def run_cli_loop(retriever, llm):
    """å‘½ä»¤è¡Œé—®ç­”å¾ªç¯ - æ”¯æŒçŸ¥è¯†åº“æ£€ç´¢å’Œç½‘ç»œæœç´¢"""
    
    # åˆå§‹åŒ–ç½‘ç»œæœç´¢å·¥å…·
    web_search = WebSearchTool(max_results=5)
    
    print("\n" + "="*60)
    print("ğŸ¤ æ¬¢è¿ä½¿ç”¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("="*60)
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
    print("  ğŸ“š ç›´æ¥æé—® â†’ ä»çŸ¥è¯†åº“æ£€ç´¢å›ç­”")
    print("  ğŸŒ @æœç´¢ [é—®é¢˜] â†’ è”ç½‘æœç´¢å®æ—¶ä¿¡æ¯")
    print("  ğŸ”„ @æ··åˆ [é—®é¢˜] â†’ åŒæ—¶ä½¿ç”¨çŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢")
    print("  âŒ è¾“å…¥ exit æˆ– quit â†’ é€€å‡ºç³»ç»Ÿ")
    print("\n" + "="*60)
    
    while True:
        query = input("\nğŸ§¾ ä½ çš„é—®é¢˜ï¼š").strip()
        
        if query.lower() in {"exit", "quit"}:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        
        if not query:
            print("âš ï¸  è¯·è¾“å…¥é—®é¢˜")
            continue
        
        try:
            # åˆ¤æ–­æœç´¢æ¨¡å¼
            if query.startswith("@æœç´¢"):
                # çº¯ç½‘ç»œæœç´¢æ¨¡å¼
                search_query = query.replace("@æœç´¢", "").strip()
                if not search_query:
                    print("âš ï¸  è¯·è¾“å…¥æœç´¢å†…å®¹ï¼Œä¾‹å¦‚ï¼š@æœç´¢ Pythonæœ€æ–°ç‰ˆæœ¬")
                    continue
                
                print(f"\nğŸŒ è”ç½‘æœç´¢æ¨¡å¼ï¼š{search_query}")
                web_context = web_search.search(search_query)
                
                # ä½¿ç”¨ç½‘ç»œæœç´¢ç»“æœ
                prompt = f"æ ¹æ®ä»¥ä¸‹äº’è”ç½‘æœç´¢ç»“æœå›ç­”é—®é¢˜ï¼š\n\n{web_context}\n\né—®é¢˜ï¼š{search_query}\n\nè¯·ç”¨ä¸­æ–‡ç®€æ´åœ°æ€»ç»“å›ç­”ï¼š"
                
            elif query.startswith("@æ··åˆ"):
                # æ··åˆæœç´¢æ¨¡å¼ï¼ˆçŸ¥è¯†åº“ + ç½‘ç»œï¼‰
                search_query = query.replace("@æ··åˆ", "").strip()
                if not search_query:
                    print("âš ï¸  è¯·è¾“å…¥æœç´¢å†…å®¹ï¼Œä¾‹å¦‚ï¼š@æ··åˆ Pythoné¢è¯•é¢˜")
                    continue
                
                print(f"\nğŸ”„ æ··åˆæœç´¢æ¨¡å¼ï¼š{search_query}")
                print("  ğŸ“š æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“...")
                relevant_docs = retriever.invoke(search_query)
                kb_context = "\n\n".join([doc.page_content for doc in relevant_docs])
                
                print("  ğŸŒ æ­£åœ¨æœç´¢äº’è”ç½‘...")
                web_context = web_search.search(search_query)
                
                # åˆå¹¶ä¸¤ç§æ¥æº
                prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ã€çŸ¥è¯†åº“å†…å®¹ã€‘
{kb_context}

ã€äº’è”ç½‘æœç´¢ç»“æœã€‘
{web_context}

é—®é¢˜ï¼š{search_query}

è¯·ç»¼åˆä»¥ä¸Šä¿¡æ¯ç”¨ä¸­æ–‡å›ç­”ï¼š"""
                
            else:
                # é»˜è®¤æ¨¡å¼ï¼šçŸ¥è¯†åº“æ£€ç´¢
                print(f"\nğŸ“š çŸ¥è¯†åº“æ£€ç´¢æ¨¡å¼")
                relevant_docs = retriever.invoke(query)
                context = "\n\n".join([doc.page_content for doc in relevant_docs])
                
                prompt = f"æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{query}\n\nå›ç­”ï¼š"
            
            # è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
            print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
            answer = llm.generate(prompt)
            print(f"\nğŸ’¬ å›ç­”ï¼š\n{answer}\n")
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  æ“ä½œå·²å–æ¶ˆ")
            continue
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            print("è¯·é‡è¯•æˆ–è¾“å…¥ exit é€€å‡º")
            continue

if __name__ == "__main__":
    retriever, llm = initialize_retriever_and_llm()
    run_cli_loop(retriever, llm)